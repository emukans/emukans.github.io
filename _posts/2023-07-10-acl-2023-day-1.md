---
layout: post
title: ACL 2023 Day 1
date: 2023-07-10 09:01 -0400
img_path: /assets/post/acl2023-1
categories: [Notes]
tags: [acl2023]
---
# Welcome
[List](https://2023.aclweb.org/program/best_papers/#outstanding-papers) of outstanding papers

Efficiency and reproducibility

The key recommendations
* alignment btw. experiments and hypotheses
* Engourage model release

Is the LLMs is the future?
The amount of papers, that are utilizing LLMs is growing.

Make peer review more robust
* collect data for research
* Encourage AI support and education
* Facilitate decision making

# Keynote by Geoffrey Hinton

In 1972, NN could not do true recursion

The solution is to use an associative memory with fast adaptign weights as a stack that stores the details of higher level calls

## A question of Scale
Symbolic AI researches were confident that large NN fails

Do LLMs understand what they are saying?
The old tests SHRDLU, Turings, Winograd sentences are outdated and not valid for modern LLMs

GPT-4 passes the Sutskever test (painted rooms)

The nature of understandings...

All the information in the data is contained in the complete higher-order statistics, so saying LLMS "just statistical" is completely vacuous.

Understanding is much better when some statement is written as a set of simple things interacting

## The first netural net language model (1985)
* It was the first time backpropagation was used to learn word embeddings
* Because it was so simple it was easy to understand how it works

## What the network learns


## Last few years of investigation
* Digital nn may be a much better form of intelligence that biological brain

## Conventional computing
Computers are more reliable and designed to do the exactly what we want.

Problems for mortal computation
* Backpropagation needs an exact model of the forward pass, so it connot be used.

## Weight or gradient sharing
If the individual agents all share exactly the same weights, ...

## Distillation
Could be used to share knowledge

Digital computation: use weight-sharing to share knowledge rapidly between many copies of the same model running


## LLMs
LLMs use digital computation and weight-sharing

But each copy of an LLM acquires its knowledge from humans by using a very inefficient form of distillation

## Super-intelligence
What would happen if large neural nets acquire knowledge directly from the world?


# Plenary session
## Best papers

# Spotlight findings
East: https://drive.google.com/drive/folders/1irDegUXggjjq227Gs4VUnkNtZqJKETUA
Centre: https://drive.google.com/drive/folders/1bVua1nuziiSG1DMOPAMke9w4C0n_S6yE
West: https://drive.google.com/drive/folders/14tH5qTF-JtEmKZbzZZmLFbdbBG9REx8F

## On the expressivity role of LayerNorm in Transformers' attention
The work tries to interpret LayerNorm geometrically.

## EmbedTextNet: Dimension Reduction with Weighted Reconstruction and Correlation Losses for Efficient Text Embedding
Website: 

## NAS for PEFT of LLMs
For LoRA the best layers to fine-tune are the middle layers

## Which examples should be multiply annotated?  Active learning when annotators may disagree.

## Know where you're going: Meta-Learning for PEFT (Thursday)

## Distilling Step-by-Step (Thursday)

## Not enough data to pre-train your LM? MT to the rescue
Is MT-based data an alternative to real data for LMs? (Yes)
Can adding translated data to real data help improve the resulting LM? (Yes, but ...)

## LMs do not recognize identifier swaps in python (Thursday)

## Do all tasks benefit equally from LLM instruction tuning? (Thursday)

## Scaling laws for BERT in Low-Resource settings
No scaling laws for small data.

## LLMs with controllable working Memory
Larger models may ignore relevant context

## What In-Context Learning "Learns" In-Context

## Recipes for Sequential Pre-training of Multilingual Encoder and Seq2Seq Models

## Residual Prompt Tuning

## Data-Efficient Finetuning Using Cross-Task Nearest Neighbors

## Honey I Shrunk the Language: Language Model Begavior at Reduced Scale (Thu)

# Medical 
Uses chatbots for question answering (~3M users).
Backed by ChatGPT via Microsoft (because it should have commercial licence)
Gracia?

Question-answer pairs. Somebody need to approve the answer.
LLM should not produce something from their own knowledge.

LMQL?


A segmentation model is running for cardiology. Segmentation across different layers. It takes 30 seconds to run.
Running for 2 years. Identifies heart attacks.

Collected own data and manually annotated for years! (20 years of data)

Issues:
* No single governance across the hospitals
* A lot of effort is spent on model support. There's a daily routine set for a QA.


Backgeneration: You have an output. Ask LLM to generate the input for that. Then check your model could generate the same output, i.e., find the same parameters.


Unilization management. Finding criterias and make evidence. Then a human should confirm it.
Thousands of human annotated evidences.
